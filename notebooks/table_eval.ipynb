{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96f28a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "make_lowlevel_tables.py\n",
    "\n",
    "Builds low level fidelity tables for each dataset.\n",
    "Rows = Method with an Implant column\n",
    "Columns = metrics\n",
    "One LaTeX table per dataset.\n",
    "\n",
    "Edit DATASET_PATHS near the bottom before running.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import json\n",
    "import pickle\n",
    "from typing import Dict, Union, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder, CocoDetection\n",
    "from torchvision.datasets.folder import default_loader\n",
    "\n",
    "import cv2\n",
    "import piq\n",
    "\n",
    "# Local project imports\n",
    "sys.path.append('./..')\n",
    "sys.path.append('./../..')\n",
    "from dynaphos import utils\n",
    "from dynaphos.simulator import GaussianSimulator as PhospheneSimulator\n",
    "from phosphene.uniformity import DynamicAmplitudeNormalizer\n",
    "from phosphene.density import VisualFieldMapper\n",
    "from spatial_frequency.components.SeparableModulated2d import SeparableModulatedConv2d\n",
    "from utils import robust_percentile_normalization  # uses your existing implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffe21d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- Determinism and device -------------\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.use_deterministic_algorithms(False)\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# ------------- Transforms -------------\n",
    "rgb_weights = torch.tensor([0.2126, 0.7152, 0.0722]).view(3, 1, 1)\n",
    "to_weighted_grayscale = transforms.Lambda(lambda img: (img * rgb_weights).sum(dim=0, keepdim=True))\n",
    "\n",
    "T_IMG = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    to_weighted_grayscale,   # -> [1, H, W], in [0, 1]\n",
    "])\n",
    "\n",
    "IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".ppm\", \".bmp\", \".pgm\", \".tif\", \".tiff\", \".webp\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22d31051",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlatImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Recursively loads all image files under root. Ignores labels.\n",
    "    Returns (tensor, 0).\n",
    "    \"\"\"\n",
    "    def __init__(self, root: str, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.paths = []\n",
    "        for dirpath, _, fnames in os.walk(root):\n",
    "            for f in fnames:\n",
    "                if os.path.splitext(f)[1].lower() in IMG_EXTS:\n",
    "                    self.paths.append(os.path.join(dirpath, f))\n",
    "        if len(self.paths) == 0:\n",
    "            raise FileNotFoundError(f\"No images found under {root}\")\n",
    "        self.loader = default_loader\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.loader(self.paths[idx])\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, 0\n",
    "\n",
    "\n",
    "def make_coco_loader(data_root: str, split: str = \"val2017\",\n",
    "                     batch_size: int = 1, shuffle: bool = False) -> DataLoader:\n",
    "    img_dir = os.path.join(data_root, split)\n",
    "    ann_file = os.path.join(data_root, \"annotations\", f\"instances_{split}.json\")\n",
    "    if not os.path.exists(img_dir):\n",
    "        raise FileNotFoundError(f\"COCO images not found at {img_dir}\")\n",
    "    if not os.path.exists(ann_file):\n",
    "        raise FileNotFoundError(f\"COCO annotations not found at {ann_file}\")\n",
    "    ds = CocoDetection(root=img_dir, annFile=ann_file, transform=T_IMG)\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "\n",
    "def make_lapa_loader(root: str, batch_size: int = 1, shuffle: bool = False) -> DataLoader:\n",
    "    try:\n",
    "        ds = ImageFolder(root, transform=T_IMG)\n",
    "        if len(ds) == 0:\n",
    "            raise FileNotFoundError(\"ImageFolder found no images\")\n",
    "    except Exception:\n",
    "        ds = FlatImageDataset(root, transform=T_IMG)\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "\n",
    "def make_sun_loader(root: str, batch_size: int = 1, shuffle: bool = False) -> DataLoader:\n",
    "    try:\n",
    "        ds = ImageFolder(root, transform=T_IMG)\n",
    "        if len(ds) == 0:\n",
    "            raise FileNotFoundError(\"ImageFolder found no images\")\n",
    "    except Exception:\n",
    "        ds = FlatImageDataset(root, transform=T_IMG)\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "def build_dataset_loaders(paths: Dict[str, str]) -> Dict[str, DataLoader]:\n",
    "    loaders = {}\n",
    "    if \"COCO\" in paths:\n",
    "        loaders[\"COCO\"] = make_coco_loader(paths[\"COCO\"], split=\"val2017\", batch_size=1, shuffle=False)\n",
    "    if \"LaPa\" in paths:\n",
    "        loaders[\"LaPa\"] = make_lapa_loader(paths[\"LaPa\"], batch_size=1, shuffle=False)\n",
    "    if \"SUN\" in paths:\n",
    "        loaders[\"SUN\"] = make_sun_loader(paths[\"SUN\"], batch_size=1, shuffle=False)\n",
    "    return loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0281229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- Implant schemes -------------\n",
    "SCHEMES: List[Tuple[str, str, float]] = [\n",
    "    (\"1 Utah\", \"../electrode_schemes/1utaharray.pickle\",                 0.4),\n",
    "    (\"Utah RFs\", \"../electrode_schemes/utahRFs.pickle\",                  6.0),\n",
    "    (\"4 Utah\", \"../electrode_schemes/4utaharrays.pickle\",               16.0),\n",
    "    (\"Uniform 1024\", \"../electrode_schemes/defaultcoordinatemap_1024.pickle\", 16.0),\n",
    "    (\"Neuralink\", \"../electrode_schemes/neuralink.pickle\",              25.0),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85cb0ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- SCAPE and simulation helpers -------------\n",
    "def dilation3x3(img: torch.Tensor, kernel: torch.Tensor = None) -> torch.Tensor:\n",
    "    if kernel is None:\n",
    "        kernel = torch.tensor([[[[0, 1, 0],\n",
    "                                 [1, 1, 1],\n",
    "                                 [0, 1, 0]]]], device=img.device, dtype=img.dtype)\n",
    "    return torch.clamp(torch.nn.functional.conv2d(img, kernel, padding=1), 0, 1)\n",
    "\n",
    "\n",
    "def rand_perlin_2d(shape: Tuple[int, int], res: Tuple[int, int],\n",
    "                   fade=lambda t: 6*t**5 - 15*t**4 + 10*t**3) -> torch.Tensor:\n",
    "    H, W = shape\n",
    "    delta = (res[0] / H, res[1] / W)\n",
    "    d = (H // res[0], W // res[1])\n",
    "    grid = torch.stack(torch.meshgrid(torch.arange(0, res[0], delta[0]),\n",
    "                                      torch.arange(0, res[1], delta[1]),\n",
    "                                      indexing='ij'), dim=-1) % 1\n",
    "    angles = 2 * math.pi * torch.rand(res[0] + 1, res[1] + 1)\n",
    "    gradients = torch.stack((torch.cos(angles), torch.sin(angles)), dim=-1)\n",
    "\n",
    "    def tile_grads(s1, s2):\n",
    "        return gradients[s1[0]:s1[1], s2[0]:s2[1]].repeat_interleave(d[0], 0).repeat_interleave(d[1], 1)\n",
    "\n",
    "    def dot(grad, shift):\n",
    "        g = grad[:H, :W]\n",
    "        return (torch.stack((grid[:H, :W, 0] + shift[0], grid[:H, :W, 1] + shift[1]), dim=-1) * g).sum(dim=-1)\n",
    "\n",
    "    n00 = dot(tile_grads([0, -1], [0, -1]), [0, 0])\n",
    "    n10 = dot(tile_grads([1, None], [0, -1]), [-1, 0])\n",
    "    n01 = dot(tile_grads([0, -1], [1, None]), [0, -1])\n",
    "    n11 = dot(tile_grads([1, None], [1, None]), [-1, -1])\n",
    "    t = fade(grid[:H, :W])\n",
    "    return math.sqrt(2) * torch.lerp(torch.lerp(n00, n10, t[..., 0]), torch.lerp(n01, n11, t[..., 0]), t[..., 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0baacc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_methods(orig_01: torch.Tensor, mod_layer: SeparableModulatedConv2d) -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    orig_01: [1, 1, H, W] in [0, 1]\n",
    "    returns dict of method name -> stimulus [1, 1, H, W] in [0, 1]\n",
    "    \"\"\"\n",
    "    # SCAPE DoG\n",
    "    dog = mod_layer(orig_01).detach()\n",
    "    dog = (dog - dog.amin()) / (dog.amax() - dog.amin() + 1e-12)\n",
    "\n",
    "    # Canny\n",
    "    npimg = (orig_01[0, 0].detach().cpu().numpy() * 255).astype(np.uint8)\n",
    "    ce = cv2.Canny(npimg, 150, 280).astype(np.float32)\n",
    "    ce = torch.from_numpy(ce).to(orig_01.device).unsqueeze(0).unsqueeze(0)\n",
    "    ce = dilation3x3(ce)\n",
    "    ce = ce / (ce.amax() + 1e-12)\n",
    "\n",
    "    # Random Perlin\n",
    "    rp = rand_perlin_2d(orig_01.shape[-2:], (4, 4)).to(orig_01.device).float()\n",
    "    rp = (rp - rp.amin()) / (rp.amax() - rp.amin() + 1e-12)\n",
    "    rp = rp.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    return {\n",
    "        \"Grayscale\": orig_01,\n",
    "        \"Canny\": ce,\n",
    "        \"DoG\": dog,\n",
    "        \"Random\": rp,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed26daec",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def simulate(simulator: PhospheneSimulator,\n",
    "             stim_img: torch.Tensor,\n",
    "             amplitude: float,\n",
    "             threshold: float,\n",
    "             weights: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    stim_img: [1, 1, H, W] in [0, 1]\n",
    "    returns phosphenes [1, 1, H, W]\n",
    "    \"\"\"\n",
    "    torch.use_deterministic_algorithms(False)\n",
    "    simulator.reset()\n",
    "    elec = simulator.sample_stimulus(stim_img, rescale=True)  # [N]\n",
    "    elec = robust_percentile_normalization(\n",
    "        elec, amplitude, threshold=threshold,\n",
    "        low_perc=5, high_perc=90, gamma=1/3\n",
    "    )\n",
    "    elec = elec * weights\n",
    "    phos = simulator(elec)\n",
    "    if phos.dim() == 2:\n",
    "        phos = phos.unsqueeze(0).unsqueeze(0)\n",
    "    elif phos.dim() == 3:\n",
    "        phos = phos.unsqueeze(0)\n",
    "    return phos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0263ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sigma_map(simulator: PhospheneSimulator) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Builds sigma map in pixels using KDE with k=16, alpha=1.0 and beta=0.55.\n",
    "    \"\"\"\n",
    "    mapper = VisualFieldMapper(simulator=simulator)\n",
    "    dens = mapper.build_density_map_kde(k=16, alpha=1.0, total_phosphenes=simulator.num_phosphenes)\n",
    "    try:\n",
    "        sigma_pix = mapper.build_sigma_map_from_density(dens, space=\"pixel\", beta=0.55)\n",
    "    except TypeError:\n",
    "        # If your mapper has beta baked in, call without it\n",
    "        sigma_pix = mapper.build_sigma_map_from_density(dens, space=\"pixel\")\n",
    "    sigma_map_tensor = torch.tensor(sigma_pix, device=DEVICE, dtype=torch.float32)\n",
    "    return sigma_map_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f234fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- Metrics -------------\n",
    "def make_metric_objects(keys: Tuple[str, ...]) -> Dict[str, torch.nn.Module]:\n",
    "    objs = {}\n",
    "    for key in keys:\n",
    "        if key == 'fsim':\n",
    "            objs[key] = piq.FSIMLoss(chromatic=False, min_length=7, scales=4).to(DEVICE)\n",
    "        elif key == 'pieapp':\n",
    "            objs[key] = piq.PieAPP().to(DEVICE)\n",
    "        elif key == 'content':\n",
    "            objs[key] = piq.ContentLoss(feature_extractor='vgg19',\n",
    "                                        normalize_features=False,\n",
    "                                        layers=['relu2_2'],\n",
    "                                        distance='swd').to(DEVICE)\n",
    "        elif key == 'srsim':\n",
    "            objs[key] = piq.SRSIMLoss().to(DEVICE)\n",
    "        elif key == 'vsi':\n",
    "            objs[key] = piq.VSILoss().to(DEVICE)\n",
    "        elif key == 'mdsi':\n",
    "            objs[key] = piq.MDSILoss().to(DEVICE)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown metric key: {key}\")\n",
    "    return objs\n",
    "\n",
    "\n",
    "def safe_loss(loss_fn: torch.nn.Module, x: torch.Tensor, y: torch.Tensor) -> float:\n",
    "    x = x.clamp(0, 1)\n",
    "    y = y.clamp(0, 1)\n",
    "    try:\n",
    "        v = loss_fn(x, y).detach().item()\n",
    "        return float(v)\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] metric {type(loss_fn).__name__} failed: {e}\")\n",
    "        return float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9518235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- Evaluation core -------------\n",
    "def eval_dataset_to_table(dataset_name: str,\n",
    "                          data_loader: DataLoader,\n",
    "                          schemes: List[Tuple[str, str, float]],\n",
    "                          params_path: str = \"../config/params.yaml\",\n",
    "                          max_images: int = 200,\n",
    "                          metrics: Tuple[str, ...] = ('ssim', 'fsim', 'mdsi', 'vsi', 'srsim', 'content'),\n",
    "                          include_se: bool = True,\n",
    "                          verbose: bool = True) -> Tuple[pd.DataFrame, str]:\n",
    "    \"\"\"\n",
    "    Runs SCAPE for each scheme, simulates phosphenes for four methods, compares to original with metrics.\n",
    "    Returns a tall DataFrame (index = Method, Implant) and a LaTeX table string.\n",
    "    \"\"\"\n",
    "    params0 = utils.load_params(params_path)  # keep as template\n",
    "    metric_objs = make_metric_objects(metrics)\n",
    "    METHODS_ORDER = [\"Grayscale\", \"Canny\", \"DoG\", \"Random\"]\n",
    "\n",
    "    # Preload a fixed list of images\n",
    "    images: List[torch.Tensor] = []\n",
    "    for i, (img, _) in enumerate(data_loader):\n",
    "        img = img.to(DEVICE)\n",
    "        images.append(img)\n",
    "        if max_images is not None and len(images) >= max_images:\n",
    "            break\n",
    "    if len(images) == 0:\n",
    "        raise RuntimeError(f\"No images in loader for dataset {dataset_name}\")\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for scheme_name, pkl_path, view_angle in schemes:\n",
    "        if not os.path.exists(pkl_path):\n",
    "            print(f\"[skip] {scheme_name}: missing {pkl_path}\")\n",
    "            continue\n",
    "\n",
    "        # Load electrode coordinates\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            coords = pickle.load(f)\n",
    "\n",
    "        # Build simulator\n",
    "        params = utils.load_params(params_path)\n",
    "        params['run']['view_angle'] = float(view_angle)\n",
    "        simulator = PhospheneSimulator(params, coords)\n",
    "        amplitude = params['sampling']['stimulus_scale']\n",
    "        threshold = params['thresholding']['rheobase']\n",
    "\n",
    "        # Amplitude normalization per scheme\n",
    "        stim_init = amplitude * torch.ones(simulator.num_phosphenes, device=DEVICE)\n",
    "        normalizer = DynamicAmplitudeNormalizer(\n",
    "            simulator=simulator,\n",
    "            base_size=3, scale=1e-4,\n",
    "            A_min=0, A_max=amplitude,\n",
    "            learning_rate=0.002, steps=2000, target=None\n",
    "        )\n",
    "        _ = normalizer.run(stim_init, verbose=False)\n",
    "        weights = normalizer.weights.detach()\n",
    "\n",
    "        # SCAPE DoG\n",
    "        sigma_map = build_sigma_map(simulator)\n",
    "        mod_layer = SeparableModulatedConv2d(in_channels=1, sigma_map=sigma_map).to(DEVICE).eval()\n",
    "\n",
    "        # Accumulators for mean and standard error\n",
    "        n = 0\n",
    "        sums = {mkey: {meth: 0.0 for meth in METHODS_ORDER} for mkey in metrics}\n",
    "        sumsq = {mkey: {meth: 0.0 for meth in METHODS_ORDER} for mkey in metrics}\n",
    "\n",
    "        for img in images:\n",
    "            orig = img  # [1,1,H,W] in [0,1]\n",
    "\n",
    "            # Build method stimuli\n",
    "            stim_dict = build_methods(orig, mod_layer)\n",
    "\n",
    "            # Simulate phosphenes\n",
    "            phos_dict = {meth: simulate(simulator, stim_dict[meth], amplitude, threshold, weights)\n",
    "                         for meth in METHODS_ORDER}\n",
    "\n",
    "            # Metrics vs original\n",
    "            for mkey, loss_fn in metric_objs.items():\n",
    "                for meth in METHODS_ORDER:\n",
    "                    val = safe_loss(loss_fn, orig, phos_dict[meth])\n",
    "                    if not math.isnan(val):\n",
    "                        sums[mkey][meth] += val\n",
    "                        sumsq[mkey][meth] += val * val\n",
    "\n",
    "            n += 1\n",
    "\n",
    "        # Compute mean and se\n",
    "        for meth in METHODS_ORDER:\n",
    "            row = {\"Method\": meth, \"Implant\": scheme_name}\n",
    "            for mkey in metrics:\n",
    "                mean = sums[mkey][meth] / max(1, n)\n",
    "                if include_se and n > 1:\n",
    "                    var_n = max(0.0, (sumsq[mkey][meth] - n * mean * mean) / (n - 1))\n",
    "                    se = math.sqrt(var_n / n)\n",
    "                    row[mkey] = (mean, se)\n",
    "                else:\n",
    "                    row[mkey] = (mean, None) if include_se else mean\n",
    "            rows.append(row)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"[done] {dataset_name} × {scheme_name}: {n} images\")\n",
    "\n",
    "    # Build DataFrame\n",
    "    df = pd.DataFrame(rows)\n",
    "    df = df.set_index([\"Method\", \"Implant\"]).sort_index()\n",
    "\n",
    "    # If include_se, format as mean ± se strings for display\n",
    "    if include_se:\n",
    "        disp = pd.DataFrame(index=df.index)\n",
    "        for col in [c for c in df.columns if c not in (\"Method\", \"Implant\")]:\n",
    "            def fmt(x):\n",
    "                mean, se = x\n",
    "                if se is None:\n",
    "                    return f\"{mean:.3f}\"\n",
    "                return f\"{mean:.3f} ± {se:.3f}\"\n",
    "            disp[col] = df[col].map(fmt)\n",
    "        df_for_tex = disp\n",
    "    else:\n",
    "        df_for_tex = df.applymap(lambda x: f\"{x:.3f}\")\n",
    "\n",
    "    latex = df_for_tex.to_latex(\n",
    "        escape=True,\n",
    "        caption=f\"Low level fidelity on {dataset_name}. Distances, lower is better.\",\n",
    "        label=f\"tab:low_{dataset_name.lower()}\",\n",
    "        index=True,\n",
    "        multicolumn=False,\n",
    "        multicolumn_format='c',\n",
    "        column_format='ll' + 'c' * len(df_for_tex.columns)\n",
    "    )\n",
    "\n",
    "    return df, latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "641aa490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Edit these paths\n",
    "    DATASET_PATHS = {\n",
    "        \"COCO\": \"/projects/prjs0344/Dynaphos/data/coco\",\n",
    "        \"LaPa\": \"/projects/prjs0344/Dynaphos/data/example_faces_LaPa\",\n",
    "        \"SUN\":  \"/projects/prjs0344/Dynaphos/data/SUN/SUN397\",\n",
    "    }\n",
    "\n",
    "    loaders = build_dataset_loaders(DATASET_PATHS)\n",
    "\n",
    "    # Metrics you want as columns\n",
    "    METRICS = ('fsim', 'pieapp', 'content', 'srsim', 'vsi', 'mdsi')\n",
    "\n",
    "    results: Dict[str, Tuple[pd.DataFrame, str]] = {}\n",
    "    for ds_name, loader in loaders.items():\n",
    "        df_table, latex = eval_dataset_to_table(\n",
    "            dataset_name=ds_name,\n",
    "            data_loader=loader,\n",
    "            schemes=SCHEMES,\n",
    "            params_path=\"../config/params.yaml\",\n",
    "            max_images=200,             # set None to use full split\n",
    "            metrics=METRICS,\n",
    "            include_se=True,\n",
    "            verbose=True\n",
    "        )\n",
    "        results[ds_name] = (df_table, latex)\n",
    "\n",
    "        csv_path = f\"lowlevel_{ds_name.lower()}.csv\"\n",
    "        tex_path = f\"lowlevel_{ds_name.lower()}.tex\"\n",
    "        df_table.to_csv(csv_path)\n",
    "        with open(tex_path, \"w\") as f:\n",
    "            f.write(latex)\n",
    "        print(f\"Wrote {csv_path} and {tex_path}\")\n",
    "\n",
    "    # Optional: print LaTeX to console\n",
    "    for ds_name, (_, latex) in results.items():\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"{ds_name} LaTeX table\")\n",
    "        print(\"=\" * 80)\n",
    "        print(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67bb0964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.75s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mappel/miniconda3/envs/ML/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mappel/miniconda3/envs/ML/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/mappel/miniconda3/envs/ML/lib/python3.8/site-packages/piq/pieapp.py:171: UserWarning: The original PieAPP supports only RGB images.The input images were converted to RGB by copying the grey channel 3 times.\n",
      "  warnings.warn('The original PieAPP supports only RGB images.'\n",
      "/home/mappel/miniconda3/envs/ML/lib/python3.8/site-packages/piq/vsi.py:63: UserWarning: The original VSI supports only RGB images. The input images were converted to RGB by copying the grey channel 3 times.\n",
      "  warnings.warn('The original VSI supports only RGB images. The input images were converted to RGB by copying '\n",
      "/home/mappel/miniconda3/envs/ML/lib/python3.8/site-packages/piq/mdsi.py:66: UserWarning: The original MDSI supports only RGB images. The input images were converted to RGB by copying the grey channel 3 times.\n",
      "  warnings.warn('The original MDSI supports only RGB images. The input images were converted to RGB by copying '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[done] COCO × 1 Utah: 200 images\n",
      "[done] COCO × Utah RFs: 200 images\n",
      "[done] COCO × 4 Utah: 200 images\n",
      "[done] COCO × Uniform 1024: 200 images\n",
      "[done] COCO × Neuralink: 200 images\n",
      "Wrote lowlevel_coco.csv and lowlevel_coco.tex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mappel/miniconda3/envs/ML/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mappel/miniconda3/envs/ML/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/mappel/miniconda3/envs/ML/lib/python3.8/site-packages/piq/pieapp.py:171: UserWarning: The original PieAPP supports only RGB images.The input images were converted to RGB by copying the grey channel 3 times.\n",
      "  warnings.warn('The original PieAPP supports only RGB images.'\n",
      "/home/mappel/miniconda3/envs/ML/lib/python3.8/site-packages/piq/vsi.py:63: UserWarning: The original VSI supports only RGB images. The input images were converted to RGB by copying the grey channel 3 times.\n",
      "  warnings.warn('The original VSI supports only RGB images. The input images were converted to RGB by copying '\n",
      "/home/mappel/miniconda3/envs/ML/lib/python3.8/site-packages/piq/mdsi.py:66: UserWarning: The original MDSI supports only RGB images. The input images were converted to RGB by copying the grey channel 3 times.\n",
      "  warnings.warn('The original MDSI supports only RGB images. The input images were converted to RGB by copying '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[done] LaPa × 1 Utah: 15 images\n",
      "[done] LaPa × Utah RFs: 15 images\n",
      "[done] LaPa × 4 Utah: 15 images\n",
      "[done] LaPa × Uniform 1024: 15 images\n",
      "[done] LaPa × Neuralink: 15 images\n",
      "Wrote lowlevel_lapa.csv and lowlevel_lapa.tex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mappel/miniconda3/envs/ML/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mappel/miniconda3/envs/ML/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/mappel/miniconda3/envs/ML/lib/python3.8/site-packages/piq/pieapp.py:171: UserWarning: The original PieAPP supports only RGB images.The input images were converted to RGB by copying the grey channel 3 times.\n",
      "  warnings.warn('The original PieAPP supports only RGB images.'\n",
      "/home/mappel/miniconda3/envs/ML/lib/python3.8/site-packages/piq/vsi.py:63: UserWarning: The original VSI supports only RGB images. The input images were converted to RGB by copying the grey channel 3 times.\n",
      "  warnings.warn('The original VSI supports only RGB images. The input images were converted to RGB by copying '\n",
      "/home/mappel/miniconda3/envs/ML/lib/python3.8/site-packages/piq/mdsi.py:66: UserWarning: The original MDSI supports only RGB images. The input images were converted to RGB by copying the grey channel 3 times.\n",
      "  warnings.warn('The original MDSI supports only RGB images. The input images were converted to RGB by copying '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[done] SUN × 1 Utah: 200 images\n",
      "[done] SUN × Utah RFs: 200 images\n",
      "[done] SUN × 4 Utah: 200 images\n",
      "[done] SUN × Uniform 1024: 200 images\n",
      "[done] SUN × Neuralink: 200 images\n",
      "Wrote lowlevel_sun.csv and lowlevel_sun.tex\n",
      "\n",
      "================================================================================\n",
      "COCO LaTeX table\n",
      "================================================================================\n",
      "\\begin{table}\n",
      "\\caption{Low level fidelity on COCO. Distances, lower is better.}\n",
      "\\label{tab:low_coco}\n",
      "\\begin{tabular}{llcccccc}\n",
      "\\toprule\n",
      " &  & fsim & pieapp & content & srsim & vsi & mdsi \\\\\n",
      "Method & Implant &  &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "\\multirow[t]{5}{*}{Canny} & 1 Utah & 0.499 ± 0.006 & 1.052 ± 0.091 & 6.303 ± 0.125 & 0.434 ± 0.004 & 0.221 ± 0.003 & 0.409 ± 0.002 \\\\\n",
      " & 4 Utah & 0.525 ± 0.007 & 1.548 ± 0.112 & 5.846 ± 0.131 & 0.480 ± 0.005 & 0.259 ± 0.004 & 0.372 ± 0.001 \\\\\n",
      " & Neuralink & 0.500 ± 0.007 & 2.631 ± 0.118 & 6.350 ± 0.124 & 0.421 ± 0.005 & 0.244 ± 0.003 & 0.381 ± 0.001 \\\\\n",
      " & Uniform 1024 & 0.457 ± 0.006 & 4.698 ± 0.135 & 4.854 ± 0.074 & 0.356 ± 0.004 & 0.230 ± 0.003 & 0.407 ± 0.001 \\\\\n",
      " & Utah RFs & 0.530 ± 0.008 & 1.711 ± 0.121 & 4.876 ± 0.133 & 0.485 ± 0.005 & 0.261 ± 0.004 & 0.364 ± 0.001 \\\\\n",
      "\\cline{1-8}\n",
      "\\multirow[t]{5}{*}{DoG} & 1 Utah & 0.506 ± 0.006 & 1.336 ± 0.080 & 6.092 ± 0.135 & 0.443 ± 0.004 & 0.224 ± 0.003 & 0.419 ± 0.002 \\\\\n",
      " & 4 Utah & 0.527 ± 0.007 & 2.209 ± 0.098 & 8.035 ± 0.123 & 0.483 ± 0.004 & 0.263 ± 0.003 & 0.403 ± 0.001 \\\\\n",
      " & Neuralink & 0.524 ± 0.007 & 3.947 ± 0.092 & 9.653 ± 0.130 & 0.475 ± 0.004 & 0.276 ± 0.003 & 0.476 ± 0.003 \\\\\n",
      " & Uniform 1024 & 0.554 ± 0.002 & 6.986 ± 0.094 & 6.328 ± 0.120 & 0.449 ± 0.003 & 0.296 ± 0.002 & 0.572 ± 0.003 \\\\\n",
      " & Utah RFs & 0.530 ± 0.008 & 3.133 ± 0.103 & 6.521 ± 0.137 & 0.489 ± 0.005 & 0.265 ± 0.004 & 0.388 ± 0.001 \\\\\n",
      "\\cline{1-8}\n",
      "\\multirow[t]{5}{*}{Grayscale} & 1 Utah & 0.507 ± 0.006 & 1.241 ± 0.087 & 6.246 ± 0.137 & 0.443 ± 0.004 & 0.224 ± 0.003 & 0.421 ± 0.002 \\\\\n",
      " & 4 Utah & 0.527 ± 0.007 & 2.107 ± 0.102 & 7.706 ± 0.125 & 0.482 ± 0.004 & 0.262 ± 0.004 & 0.398 ± 0.001 \\\\\n",
      " & Neuralink & 0.521 ± 0.007 & 3.558 ± 0.103 & 9.664 ± 0.137 & 0.467 ± 0.004 & 0.269 ± 0.003 & 0.470 ± 0.003 \\\\\n",
      " & Uniform 1024 & 0.543 ± 0.004 & 6.539 ± 0.112 & 6.651 ± 0.136 & 0.442 ± 0.003 & 0.285 ± 0.002 & 0.559 ± 0.004 \\\\\n",
      " & Utah RFs & 0.529 ± 0.008 & 2.959 ± 0.111 & 6.339 ± 0.135 & 0.488 ± 0.005 & 0.264 ± 0.004 & 0.385 ± 0.001 \\\\\n",
      "\\cline{1-8}\n",
      "\\multirow[t]{5}{*}{Random} & 1 Utah & 0.504 ± 0.006 & 1.306 ± 0.081 & 6.085 ± 0.138 & 0.440 ± 0.004 & 0.224 ± 0.003 & 0.421 ± 0.002 \\\\\n",
      " & 4 Utah & 0.528 ± 0.007 & 2.164 ± 0.096 & 7.767 ± 0.125 & 0.485 ± 0.004 & 0.263 ± 0.003 & 0.401 ± 0.001 \\\\\n",
      " & Neuralink & 0.523 ± 0.007 & 3.448 ± 0.093 & 9.286 ± 0.131 & 0.475 ± 0.004 & 0.274 ± 0.003 & 0.469 ± 0.002 \\\\\n",
      " & Uniform 1024 & 0.555 ± 0.003 & 6.610 ± 0.093 & 6.234 ± 0.122 & 0.448 ± 0.002 & 0.297 ± 0.002 & 0.569 ± 0.003 \\\\\n",
      " & Utah RFs & 0.530 ± 0.008 & 3.027 ± 0.101 & 6.286 ± 0.139 & 0.490 ± 0.005 & 0.265 ± 0.004 & 0.386 ± 0.001 \\\\\n",
      "\\cline{1-8}\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "================================================================================\n",
      "LaPa LaTeX table\n",
      "================================================================================\n",
      "\\begin{table}\n",
      "\\caption{Low level fidelity on LaPa. Distances, lower is better.}\n",
      "\\label{tab:low_lapa}\n",
      "\\begin{tabular}{llcccccc}\n",
      "\\toprule\n",
      " &  & fsim & pieapp & content & srsim & vsi & mdsi \\\\\n",
      "Method & Implant &  &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "\\multirow[t]{5}{*}{Canny} & 1 Utah & 0.404 ± 0.013 & 0.456 ± 0.242 & 5.118 ± 0.548 & 0.359 ± 0.010 & 0.176 ± 0.008 & 0.385 ± 0.005 \\\\\n",
      " & 4 Utah & 0.430 ± 0.015 & 0.939 ± 0.331 & 4.542 ± 0.402 & 0.389 ± 0.013 & 0.199 ± 0.010 & 0.369 ± 0.004 \\\\\n",
      " & Neuralink & 0.415 ± 0.015 & 1.466 ± 0.369 & 4.316 ± 0.438 & 0.354 ± 0.014 & 0.195 ± 0.010 & 0.368 ± 0.005 \\\\\n",
      " & Uniform 1024 & 0.381 ± 0.014 & 2.800 ± 0.464 & 3.469 ± 0.230 & 0.317 ± 0.011 & 0.190 ± 0.010 & 0.376 ± 0.005 \\\\\n",
      " & Utah RFs & 0.448 ± 0.015 & 0.648 ± 0.318 & 3.922 ± 0.392 & 0.392 ± 0.010 & 0.199 ± 0.010 & 0.363 ± 0.005 \\\\\n",
      "\\cline{1-8}\n",
      "\\multirow[t]{5}{*}{DoG} & 1 Utah & 0.412 ± 0.014 & 0.903 ± 0.144 & 5.524 ± 0.489 & 0.373 ± 0.009 & 0.168 ± 0.006 & 0.427 ± 0.005 \\\\\n",
      " & 4 Utah & 0.421 ± 0.016 & 2.445 ± 0.242 & 7.636 ± 0.463 & 0.401 ± 0.011 & 0.204 ± 0.008 & 0.411 ± 0.005 \\\\\n",
      " & Neuralink & 0.443 ± 0.015 & 5.211 ± 0.202 & 10.108 ± 0.404 & 0.434 ± 0.011 & 0.237 ± 0.006 & 0.502 ± 0.006 \\\\\n",
      " & Uniform 1024 & 0.519 ± 0.006 & 8.240 ± 0.190 & 7.038 ± 0.281 & 0.454 ± 0.014 & 0.280 ± 0.006 & 0.600 ± 0.007 \\\\\n",
      " & Utah RFs & 0.425 ± 0.017 & 3.477 ± 0.269 & 6.635 ± 0.433 & 0.406 ± 0.009 & 0.206 ± 0.009 & 0.397 ± 0.004 \\\\\n",
      "\\cline{1-8}\n",
      "\\multirow[t]{5}{*}{Grayscale} & 1 Utah & 0.413 ± 0.013 & 0.797 ± 0.172 & 5.646 ± 0.514 & 0.382 ± 0.010 & 0.170 ± 0.006 & 0.431 ± 0.007 \\\\\n",
      " & 4 Utah & 0.420 ± 0.016 & 2.379 ± 0.260 & 6.979 ± 0.462 & 0.399 ± 0.011 & 0.202 ± 0.009 & 0.405 ± 0.005 \\\\\n",
      " & Neuralink & 0.437 ± 0.017 & 3.998 ± 0.224 & 9.633 ± 0.480 & 0.413 ± 0.012 & 0.226 ± 0.008 & 0.484 ± 0.007 \\\\\n",
      " & Uniform 1024 & 0.498 ± 0.011 & 7.626 ± 0.265 & 7.427 ± 0.321 & 0.432 ± 0.009 & 0.262 ± 0.005 & 0.583 ± 0.007 \\\\\n",
      " & Utah RFs & 0.423 ± 0.017 & 3.267 ± 0.249 & 5.962 ± 0.467 & 0.394 ± 0.010 & 0.203 ± 0.010 & 0.390 ± 0.004 \\\\\n",
      "\\cline{1-8}\n",
      "\\multirow[t]{5}{*}{Random} & 1 Utah & 0.410 ± 0.014 & 0.881 ± 0.169 & 5.247 ± 0.501 & 0.375 ± 0.010 & 0.169 ± 0.006 & 0.427 ± 0.006 \\\\\n",
      " & 4 Utah & 0.421 ± 0.016 & 2.426 ± 0.203 & 7.190 ± 0.419 & 0.404 ± 0.011 & 0.204 ± 0.008 & 0.409 ± 0.005 \\\\\n",
      " & Neuralink & 0.441 ± 0.015 & 4.465 ± 0.250 & 9.677 ± 0.444 & 0.424 ± 0.012 & 0.233 ± 0.006 & 0.493 ± 0.007 \\\\\n",
      " & Uniform 1024 & 0.520 ± 0.006 & 8.103 ± 0.209 & 6.472 ± 0.295 & 0.442 ± 0.010 & 0.280 ± 0.005 & 0.602 ± 0.006 \\\\\n",
      " & Utah RFs & 0.424 ± 0.017 & 3.424 ± 0.272 & 6.277 ± 0.414 & 0.401 ± 0.009 & 0.206 ± 0.009 & 0.395 ± 0.004 \\\\\n",
      "\\cline{1-8}\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "================================================================================\n",
      "SUN LaTeX table\n",
      "================================================================================\n",
      "\\begin{table}\n",
      "\\caption{Low level fidelity on SUN. Distances, lower is better.}\n",
      "\\label{tab:low_sun}\n",
      "\\begin{tabular}{llcccccc}\n",
      "\\toprule\n",
      " &  & fsim & pieapp & content & srsim & vsi & mdsi \\\\\n",
      "Method & Implant &  &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "\\multirow[t]{5}{*}{Canny} & 1 Utah & 0.524 ± 0.005 & 1.974 ± 0.073 & 6.586 ± 0.122 & 0.452 ± 0.004 & 0.231 ± 0.003 & 0.399 ± 0.001 \\\\\n",
      " & 4 Utah & 0.560 ± 0.006 & 2.746 ± 0.089 & 6.359 ± 0.129 & 0.507 ± 0.004 & 0.278 ± 0.004 & 0.361 ± 0.001 \\\\\n",
      " & Neuralink & 0.536 ± 0.006 & 3.848 ± 0.097 & 7.264 ± 0.112 & 0.452 ± 0.004 & 0.261 ± 0.003 & 0.373 ± 0.001 \\\\\n",
      " & Uniform 1024 & 0.490 ± 0.005 & 6.081 ± 0.113 & 5.411 ± 0.072 & 0.377 ± 0.003 & 0.242 ± 0.002 & 0.403 ± 0.002 \\\\\n",
      " & Utah RFs & 0.567 ± 0.006 & 3.079 ± 0.103 & 5.329 ± 0.131 & 0.517 ± 0.004 & 0.280 ± 0.004 & 0.352 ± 0.001 \\\\\n",
      "\\cline{1-8}\n",
      "\\multirow[t]{5}{*}{DoG} & 1 Utah & 0.538 ± 0.005 & 2.189 ± 0.066 & 6.192 ± 0.137 & 0.465 ± 0.004 & 0.239 ± 0.003 & 0.413 ± 0.002 \\\\\n",
      " & 4 Utah & 0.561 ± 0.006 & 3.147 ± 0.080 & 7.842 ± 0.110 & 0.506 ± 0.004 & 0.279 ± 0.003 & 0.382 ± 0.001 \\\\\n",
      " & Neuralink & 0.553 ± 0.005 & 4.606 ± 0.077 & 9.476 ± 0.115 & 0.480 ± 0.003 & 0.281 ± 0.003 & 0.457 ± 0.002 \\\\\n",
      " & Uniform 1024 & 0.559 ± 0.002 & 7.430 ± 0.077 & 6.415 ± 0.129 & 0.433 ± 0.002 & 0.285 ± 0.002 & 0.547 ± 0.003 \\\\\n",
      " & Utah RFs & 0.563 ± 0.006 & 4.314 ± 0.084 & 6.449 ± 0.116 & 0.518 ± 0.004 & 0.282 ± 0.004 & 0.369 ± 0.001 \\\\\n",
      "\\cline{1-8}\n",
      "\\multirow[t]{5}{*}{Grayscale} & 1 Utah & 0.536 ± 0.005 & 2.152 ± 0.071 & 6.458 ± 0.134 & 0.464 ± 0.004 & 0.237 ± 0.003 & 0.410 ± 0.002 \\\\\n",
      " & 4 Utah & 0.560 ± 0.006 & 3.074 ± 0.080 & 7.701 ± 0.111 & 0.506 ± 0.004 & 0.279 ± 0.003 & 0.380 ± 0.001 \\\\\n",
      " & Neuralink & 0.553 ± 0.005 & 4.238 ± 0.086 & 9.577 ± 0.132 & 0.479 ± 0.003 & 0.280 ± 0.003 & 0.455 ± 0.003 \\\\\n",
      " & Uniform 1024 & 0.564 ± 0.002 & 7.194 ± 0.084 & 7.235 ± 0.147 & 0.438 ± 0.002 & 0.290 ± 0.002 & 0.556 ± 0.003 \\\\\n",
      " & Utah RFs & 0.563 ± 0.006 & 4.031 ± 0.090 & 6.241 ± 0.128 & 0.518 ± 0.004 & 0.282 ± 0.004 & 0.366 ± 0.001 \\\\\n",
      "\\cline{1-8}\n",
      "\\multirow[t]{5}{*}{Random} & 1 Utah & 0.534 ± 0.005 & 2.172 ± 0.067 & 6.197 ± 0.137 & 0.462 ± 0.004 & 0.238 ± 0.003 & 0.411 ± 0.002 \\\\\n",
      " & 4 Utah & 0.561 ± 0.006 & 3.089 ± 0.078 & 7.549 ± 0.115 & 0.508 ± 0.004 & 0.279 ± 0.003 & 0.380 ± 0.001 \\\\\n",
      " & Neuralink & 0.553 ± 0.005 & 4.174 ± 0.079 & 9.061 ± 0.117 & 0.485 ± 0.003 & 0.281 ± 0.003 & 0.450 ± 0.002 \\\\\n",
      " & Uniform 1024 & 0.565 ± 0.002 & 7.105 ± 0.078 & 6.320 ± 0.125 & 0.436 ± 0.002 & 0.291 ± 0.001 & 0.552 ± 0.003 \\\\\n",
      " & Utah RFs & 0.564 ± 0.006 & 4.114 ± 0.084 & 6.190 ± 0.126 & 0.519 ± 0.004 & 0.282 ± 0.004 & 0.367 ± 0.001 \\\\\n",
      "\\cline{1-8}\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "631073a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[t]\n",
      "\\centering\n",
      "\\small\n",
      "\\caption{Low-level fidelity metrics on LaPa. Values are distances, lower is better.}\n",
      "\\label{tab:low_lapa}\n",
      "\\begin{tabular}{llcccccc}\n",
      "\\toprule\n",
      "Implant & Method & FSIM & PIEAPP & CONTENT & SRSIM & VSI & MDSI \\\\\n",
      "\\midrule\n",
      "\\multirow{4}*{1 Utah} & Canny & \\textbf{0.404} & \\textbf{0.456} & \\textbf{5.118} & \\textbf{0.359} & 0.176 & \\textbf{0.385} \\\\\n",
      " & DoG & 0.412 & 0.903 & 5.524 & 0.373 & \\textbf{0.168} & 0.427 \\\\\n",
      " & Grayscale & 0.413 & 0.797 & 5.646 & 0.382 & 0.170 & 0.431 \\\\\n",
      " & Random & 0.410 & 0.881 & 5.247 & 0.375 & 0.169 & 0.427 \\\\\n",
      "\\midrule\n",
      "\\multirow{4}*{4 Utah} & Canny & 0.430 & \\textbf{0.939} & \\textbf{4.542} & \\textbf{0.389} & \\textbf{0.199} & \\textbf{0.369} \\\\\n",
      " & DoG & 0.421 & 2.445 & 7.636 & 0.401 & 0.204 & 0.411 \\\\\n",
      " & Grayscale & \\textbf{0.420} & 2.379 & 6.979 & 0.399 & 0.202 & 0.405 \\\\\n",
      " & Random & 0.421 & 2.426 & 7.190 & 0.404 & 0.204 & 0.409 \\\\\n",
      "\\midrule\n",
      "\\multirow{4}*{Neuralink} & Canny & \\textbf{0.415} & \\textbf{1.466} & \\textbf{4.316} & \\textbf{0.354} & \\textbf{0.195} & \\textbf{0.368} \\\\\n",
      " & DoG & 0.443 & 5.211 & 10.108 & 0.434 & 0.237 & 0.502 \\\\\n",
      " & Grayscale & 0.437 & 3.998 & 9.633 & 0.413 & 0.226 & 0.484 \\\\\n",
      " & Random & 0.441 & 4.465 & 9.677 & 0.424 & 0.233 & 0.493 \\\\\n",
      "\\midrule\n",
      "\\multirow{4}*{Uniform 1024} & Canny & \\textbf{0.381} & \\textbf{2.800} & \\textbf{3.469} & \\textbf{0.317} & \\textbf{0.190} & \\textbf{0.376} \\\\\n",
      " & DoG & 0.519 & 8.240 & 7.038 & 0.454 & 0.280 & 0.600 \\\\\n",
      " & Grayscale & 0.498 & 7.626 & 7.427 & 0.432 & 0.262 & 0.583 \\\\\n",
      " & Random & 0.520 & 8.103 & 6.472 & 0.442 & 0.280 & 0.602 \\\\\n",
      "\\midrule\n",
      "\\multirow{4}*{Utah RFs} & Canny & 0.448 & \\textbf{0.648} & \\textbf{3.922} & \\textbf{0.392} & \\textbf{0.199} & \\textbf{0.363} \\\\\n",
      " & DoG & 0.425 & 3.477 & 6.635 & 0.406 & 0.206 & 0.397 \\\\\n",
      " & Grayscale & \\textbf{0.423} & 3.267 & 5.962 & 0.394 & 0.203 & 0.390 \\\\\n",
      " & Random & 0.424 & 3.424 & 6.277 & 0.401 & 0.206 & 0.395 \\\\\n",
      "\\midrule\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def make_latex_table(csv_path: str,\n",
    "                     dataset_name: str,\n",
    "                     metrics: list,\n",
    "                     caption: str = None,\n",
    "                     label: str = None,\n",
    "                     round_digits: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Convert CSV of results into a LaTeX table string.\n",
    "    Layout: Implant (once, multirow) | Method | Metrics.\n",
    "    Bold = best (lowest) per implant and metric.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Parse values\n",
    "    def parse_val(v):\n",
    "        if isinstance(v, str):\n",
    "            v = v.strip()\n",
    "            if v.startswith(\"(\") and \",\" in v and v.endswith(\")\"):\n",
    "                mean_str = v[1:-1].split(\",\")[0]\n",
    "                try:\n",
    "                    return float(mean_str)\n",
    "                except:\n",
    "                    return np.nan\n",
    "            try:\n",
    "                return float(v)\n",
    "            except:\n",
    "                return np.nan\n",
    "        return v\n",
    "\n",
    "    for m in metrics:\n",
    "        df[m] = df[m].map(parse_val)\n",
    "\n",
    "    # Defaults\n",
    "    if caption is None:\n",
    "        caption = f\"Low-level fidelity metrics on {dataset_name}. Values are distances, lower is better.\"\n",
    "    if label is None:\n",
    "        label = f\"tab:low_{dataset_name.lower()}\"\n",
    "\n",
    "    # Start LaTeX\n",
    "    latex = []\n",
    "    latex.append(\"\\\\begin{table}[t]\")\n",
    "    latex.append(\"\\\\centering\")\n",
    "    latex.append(\"\\\\small\")\n",
    "    latex.append(f\"\\\\caption{{{caption}}}\")\n",
    "    latex.append(f\"\\\\label{{{label}}}\")\n",
    "    colspec = \"ll\" + \"c\" * len(metrics)\n",
    "    latex.append(f\"\\\\begin{{tabular}}{{{colspec}}}\")\n",
    "    latex.append(\"\\\\toprule\")\n",
    "    latex.append(\"Implant & Method & \" + \" & \".join(m.upper() for m in metrics) + \" \\\\\\\\\")\n",
    "    latex.append(\"\\\\midrule\")\n",
    "\n",
    "    # Per implant\n",
    "    for implant, group in df.groupby(\"Implant\"):\n",
    "        # best values per metric across methods\n",
    "        bests = {m: group[m].min() for m in metrics}\n",
    "\n",
    "        methods = group[\"Method\"].tolist()\n",
    "        n_methods = len(methods)\n",
    "\n",
    "        for idx, (_, row) in enumerate(group.iterrows()):\n",
    "            row_str = []\n",
    "            if idx == 0:\n",
    "                row_str.append(f\"\\\\multirow{{{n_methods}}}*{{{implant}}}\")\n",
    "            else:\n",
    "                row_str.append(\"\")  # empty for subsequent rows\n",
    "\n",
    "            row_str.append(row[\"Method\"])\n",
    "\n",
    "            for m in metrics:\n",
    "                val = row[m]\n",
    "                if pd.isna(val):\n",
    "                    s = \"-\"\n",
    "                else:\n",
    "                    sval = f\"{val:.{round_digits}f}\"\n",
    "                    if np.isclose(val, bests[m], rtol=1e-5, atol=1e-8):\n",
    "                        sval = f\"\\\\textbf{{{sval}}}\"\n",
    "                    s = sval\n",
    "                row_str.append(s)\n",
    "\n",
    "            latex.append(\" & \".join(row_str) + \" \\\\\\\\\")\n",
    "\n",
    "        latex.append(\"\\\\midrule\")\n",
    "\n",
    "    latex.append(\"\\\\bottomrule\")\n",
    "    latex.append(\"\\\\end{tabular}\")\n",
    "    latex.append(\"\\\\end{table}\")\n",
    "\n",
    "    return \"\\n\".join(latex)\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    table_tex = make_latex_table(\n",
    "        csv_path=\"lowlevel_lapa.csv\",\n",
    "        dataset_name=\"LaPa\",\n",
    "        metrics=[\"fsim\", \"pieapp\", \"content\", \"srsim\", \"vsi\", \"mdsi\"],\n",
    "        round_digits=3\n",
    "    )\n",
    "    with open(\"table_low_lapa.tex\", \"w\") as f:\n",
    "        f.write(table_tex)\n",
    "    print(table_tex)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
