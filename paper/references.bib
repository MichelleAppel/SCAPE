@article {vanderGrinten2024,
article_type = {journal},
title = {Towards biologically plausible phosphene simulation for the differentiable optimization of visual cortical prostheses},
author = {van der Grinten, Maureen and de Ruyter van Steveninck, Jaap and Lozano, Antonio and Pijnacker, Laura and Rueckauer, Bodo and Roelfsema, Pieter and van Gerven, Marcel and van Wezel, Richard and Güçlü, Umut and Güçlütürk, Yağmur},
editor = {Baker, Chris I and Barry, Michael P},
volume = 13,
year = 2024,
month = {feb},
pub_date = {2024-02-22},
pages = {e85812},
citation = {eLife 2024;13:e85812},
doi = {10.7554/eLife.85812},
url = {https://doi.org/10.7554/eLife.85812},
abstract = {Blindness affects millions of people around the world. A promising solution to restoring a form of vision for some individuals are cortical visual prostheses, which bypass part of the impaired visual pathway by converting camera input to electrical stimulation of the visual system. The artificially induced visual percept (a pattern of localized light flashes, or ‘phosphenes’) has limited resolution, and a great portion of the field’s research is devoted to optimizing the efficacy, efficiency, and practical usefulness of the encoding of visual information. A commonly exploited method is non-invasive functional evaluation in sighted subjects or with computational models by using simulated prosthetic vision (SPV) pipelines. An important challenge in this approach is to balance enhanced perceptual realism, biologically plausibility, and real-time performance in the simulation of cortical prosthetic vision. We present a biologically plausible, PyTorch-based phosphene simulator that can run in real-time and uses differentiable operations to allow for gradient-based computational optimization of phosphene encoding models. The simulator integrates a wide range of clinical results with neurophysiological evidence in humans and non-human primates. The pipeline includes a model of the retinotopic organization and cortical magnification of the visual cortex. Moreover, the quantitative effects of stimulation parameters and temporal dynamics on phosphene characteristics are incorporated. Our results demonstrate the simulator’s suitability for both computational applications such as end-to-end deep learning-based prosthetic vision optimization as well as behavioral experiments. The modular and open-source software provides a flexible simulation framework for computational, clinical, and behavioral neuroscientists working on visual neuroprosthetics.},
keywords = {simulated prosthetic vision, cortical stimulation, bionic vision, blindness, deep learning, neurotechnology, neural implants},
journal = {eLife},
issn = {2050-084X},
publisher = {eLife Sciences Publications, Ltd},
}

@article{Polimeni2006,
title = {Multi-area visuotopic map complexes in macaque striate and extra-striate cortex},
journal = {Vision Research},
volume = {46},
number = {20},
pages = {3336-3359},
year = {2006},
issn = {0042-6989},
doi = {https://doi.org/10.1016/j.visres.2006.03.006},
url = {https://www.sciencedirect.com/science/article/pii/S0042698906001428},
author = {J.R. Polimeni and M. Balasubramanian and E.L. Schwartz},
keywords = {Visual cortex, Retinotopic, Quasiconformal mapping, Topographic modeling, Topographic map complex},
abstract = {We propose that a simple, closed-form mathematical expression—the Wedge–Dipole mapping—provides a concise approximation to the full-field, two-dimensional topographic structure of macaque V1, V2, and V3. A single map function, which we term a map complex, acts as a simultaneous descriptor of all three areas. Quantitative estimation of the Wedge–Dipole parameters is provided via 2DG data of central-field V1 topography and a publicly available data set of full-field macaque V1 and V2 topography. Good quantitative agreement is obtained between the data and the model presented here. The increasing importance of fMRI-based brain imaging motivates the development of more sophisticated two-dimensional models of cortical visuotopy, in contrast to the one-dimensional approximations that have been in common use. One reason is that topography has traditionally supplied an important aspect of “ground truth,” or validation, for brain imaging, suggesting that further development of high-resolution fMRI will be facilitated by this data analysis. In addition, several important insights into the nature of cortical topography follow from this work. The presence of anisotropy in cortical magnification factor is shown to follow mathematically from the shared boundary conditions at the V1–V2 and V2–V3 borders, and therefore may not causally follow from the existence of columnar systems in these areas, as is widely assumed. An application of the Wedge–Dipole model to localizing aspects of visual processing to specific cortical areas—extending previous work in correlating V1 cortical magnification factor to retinal anatomy or visual psychophysics data—is briefly discussed.}
}

@ARTICLE{Nyquist1928,
  author={Nyquist, H.},
  journal={Transactions of the American Institute of Electrical Engineers}, 
  title={Certain Topics in Telegraph Transmission Theory}, 
  year={1928},
  volume={47},
  number={2},
  pages={617-644},
  keywords={Telegraphy;Steady-state;Frequency conversion;Circuits;Costs;Distortion;Shape;Interference;Equalizers;Telephony},
  doi={10.1109/T-AIEE.1928.5055024}}

@article {Young1987,
      author = "Richard A. Young",
      title = "The Gaussian derivative model for spatial vision: I. Retinal mechanisms",
      journal = "Spatial Vision",
      year = "1987",
      publisher = "Brill",
      address = "Leiden, The Netherlands",
      volume = "2",
      number = "4",
      doi = "10.1163/156856887X00222",
      pages=      "273 - 293",
      url = "https://brill.com/view/journals/sv/2/4/article-p273_3.xml"
}

@article {deRuytervanSteveninck2020,
	author = {de Ruyter van Steveninck, Jaap and G{\"u}{\c c}l{\"u}, Umut and van Wezel, Richard and van Gerven, Marcel},
	title = {End-to-end optimization of prosthetic vision},
	elocation-id = {2020.12.19.423601},
	year = {2020},
	doi = {10.1101/2020.12.19.423601},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {Neural prosthetics may provide a promising solution to restore visual perception in some forms of blindness. The restored prosthetic percept is rudimentary compared to normal vision and can be optimized with a variety of image preprocessing techniques to maximize relevant information transfer. Extracting the most useful features from a visual scene is a non-trivial task and optimal preprocessing choices strongly depend on the context. Despite rapid advancements in deep learning, research currently faces a difficult challenge in finding a general and automated preprocessing strategy that can be tailored to specific tasks or user requirements. In this paper we present a novel deep learning approach that explicitly addresses this issue by optimizing the entire process of phosphene generation in an end-to-end fashion. The proposed model is based on a deep auto-encoder architecture and includes a highly adjustable simulation module of prosthetic vision. In computational validation experiments we show that such an approach is able to automatically find a task-specific stimulation protocol. The presented approach is highly modular and could be extended to dynamically optimize prosthetic vision for everyday tasks and requirements of the end-user.Competing Interest StatementThe authors have declared no competing interest.},
	URL = {https://www.biorxiv.org/content/early/2020/12/21/2020.12.19.423601},
	eprint = {https://www.biorxiv.org/content/early/2020/12/21/2020.12.19.423601.full.pdf},
	journal = {bioRxiv}
}


@misc{Ronneberger2015,
      title={U-Net: Convolutional Networks for Biomedical Image Segmentation}, 
      author={Olaf Ronneberger and Philipp Fischer and Thomas Brox},
      year={2015},
      eprint={1505.04597},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1505.04597}, 
}

@misc{Hu2018,
      title={Squeeze-and-Excitation Networks}, 
      author={Jie Hu and Li Shen and Samuel Albanie and Gang Sun and Enhua Wu},
      year={2019},
      eprint={1709.01507},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1709.01507}, 
}

@misc{Yu2016,
      title={Multi-Scale Context Aggregation by Dilated Convolutions}, 
      author={Fisher Yu and Vladlen Koltun},
      year={2016},
      eprint={1511.07122},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1511.07122}, 
}

@misc{Oktay2018,
      title={Attention U-Net: Learning Where to Look for the Pancreas}, 
      author={Ozan Oktay and Jo Schlemper and Loic Le Folgoc and Matthew Lee and Mattias Heinrich and Kazunari Misawa and Kensaku Mori and Steven McDonagh and Nils Y Hammerla and Bernhard Kainz and Ben Glocker and Daniel Rueckert},
      year={2018},
      eprint={1804.03999},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1804.03999}, 
}

@article{ZiaeiNafchi2016,
   title={Mean Deviation Similarity Index: Efficient and Reliable Full-Reference Image Quality Evaluator},
   volume={4},
   ISSN={2169-3536},
   url={http://dx.doi.org/10.1109/ACCESS.2016.2604042},
   DOI={10.1109/access.2016.2604042},
   journal={IEEE Access},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Ziaei Nafchi, Hossein and Shahkolaei, Atena and Hedjam, Rachid and Cheriet, Mohamed},
   year={2016},
   pages={5579–5590} }


@ARTICLE{Wang2004,
  author={Zhou Wang and Bovik, A.C. and Sheikh, H.R. and Simoncelli, E.P.},
  journal={IEEE Transactions on Image Processing}, 
  title={Image quality assessment: from error visibility to structural similarity}, 
  year={2004},
  volume={13},
  number={4},
  pages={600-612},
  keywords={Image quality;Humans;Transform coding;Visual system;Visual perception;Data mining;Layout;Quality assessment;Degradation;Indexes},
  doi={10.1109/TIP.2003.819861}}

@ARTICLE{Zhang2014,
  author={Zhang, Lin and Shen, Ying and Li, Hongyu},
  journal={IEEE Transactions on Image Processing}, 
  title={VSI: A Visual Saliency-Induced Index for Perceptual Image Quality Assessment}, 
  year={2014},
  volume={23},
  number={10},
  pages={4270-4281},
  keywords={Visualization;Computational modeling;Indexes;Image quality;Measurement;Image color analysis;Feature extraction;Perceptual image quality assessment;visual saliency},
  doi={10.1109/TIP.2014.2346028}}

@misc{Prashnani2018,
    title={PieAPP: Perceptual Image-Error Assessment through Pairwise Preference}, 
    author={Ekta Prashnani and Hong Cai and Yasamin Mostofi and Pradeep Sen},
    year={2018},
    eprint={1806.02067},
    archivePrefix={arXiv},
    primaryClass={cs.CV},
    url={https://arxiv.org/abs/1806.02067}, 
}

@article{Wang2018, 
author = {Wang, Xiaosha and Xu, Yangwen and Wang, Yuwei and Zeng, Yi and Zhang, Jiacai and Ling, Zhen-Hua and Bi, Yanchao},
year = {2018},
month = {02},
pages = {},
title = {Representational similarity analysis reveals task-dependent semantic influence of the visual word form area},
volume = {8},
journal = {Scientific Reports},
doi = {10.1038/s41598-018-21062-0}
}

@article{Kriegeskorte2008,
author = {Kriegeskorte, Nikolaus and Mur, Marieke and Bandettini, Peter},
year = {2008},
month = {02},
pages = {4},
title = {Representational Similarity Analysis – Connecting the Branches of Systems Neuroscience},
volume = {2},
journal = {Frontiers in systems neuroscience},
doi = {10.3389/neuro.06.004.2008}
}



@INPROCEEDINGS{Liu2005,
  author={Wentai Liu and Fink, W. and Tarbell, M. and Sivaprakasam, M.},
  booktitle={2005 IEEE International Symposium on Circuits and Systems (ISCAS)}, 
  title={Image processing and interface for retinal visual prostheses}, 
  year={2005},
  volume={},
  number={},
  pages={2927-2930 Vol. 3},
  keywords={Image processing;Retina;Visual prosthesis;Implants;Visual perception;Gray-scale;Electrical stimulation;Photoreceptors;Electrodes;Image restoration},
  doi={10.1109/ISCAS.2005.1465240}}


@article{Oh2024,
  author  = {Yeonji Oh, Jonggi Hong, Jungsuk Kim},
  title   = {Retinal Prosthesis Edge Detection (RPED) Algorithm: Low-Power and Improved Visual Acuity Strategy for Artificial Retinal Implants},
  journal = {PLoS ONE},
  volume  = {19},
  number  = {6},
  pages   = {e0305132},
  year    = {2024},
  doi     = {10.1371/journal.pone.0305132},
}

@misc{Relic2022,
      title={Deep Learning-Based Perceptual Stimulus Encoder for Bionic Vision}, 
      author={Lucas Relic and Bowen Zhang and Yi-Lin Tuan and Michael Beyeler},
      year={2022},
      eprint={2203.05604},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2203.05604}, 
}

@misc{Granley2022,
      title={Hybrid Neural Autoencoders for Stimulus Encoding in Visual and Other Sensory Neuroprostheses}, 
      author={Jacob Granley and Lucas Relic and Michael Beyeler},
      year={2022},
      eprint={2205.13623},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2205.13623}, 
}


@inproceedings{Kasowski2022, series={AHs 2022},
   title={Immersive Virtual Reality Simulations of Bionic Vision},
   url={http://dx.doi.org/10.1145/3519391.3522752},
   DOI={10.1145/3519391.3522752},
   booktitle={Augmented Humans 2022},
   publisher={ACM},
   author={Kasowski, Justin and Beyeler, Michael},
   year={2022},
   month=mar, pages={82–93},
   collection={AHs 2022} }

@misc{Han2021,
      title={Deep Learning--Based Scene Simplification for Bionic Vision}, 
      author={Nicole Han and Sudhanshu Srivastava and Aiwen Xu and Devi Klein and Michael Beyeler},
      year={2021},
      eprint={2102.00297},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2102.00297}, 
}


@misc{Granley2023,
      title={Human-in-the-Loop Optimization for Deep Stimulus Encoding in Visual Prostheses}, 
      author={Jacob Granley and Tristan Fauvel and Matthew Chalk and Michael Beyeler},
      year={2023},
      eprint={2306.13104},
      archivePrefix={arXiv},
      primaryClass={q-bio.NC},
      url={https://arxiv.org/abs/2306.13104}, 
}

@ARTICLE{Zhang2011,
  author={Zhang, Lin and Zhang, Lei and Mou, Xuanqin and Zhang, David},
  journal={IEEE Transactions on Image Processing}, 
  title={FSIM: A Feature Similarity Index for Image Quality Assessment}, 
  year={2011},
  volume={20},
  number={8},
  pages={2378-2386},
  keywords={Measurement;Gabor filters;Indexes;Feature extraction;Visualization;Image color analysis;Gradient;image quality assessment (IQA);low-level feature;phase congruency (PC)},
  doi={10.1109/TIP.2011.2109730}}

@misc{Gatys2015,
      title={A Neural Algorithm of Artistic Style}, 
      author={Leon A. Gatys and Alexander S. Ecker and Matthias Bethge},
      year={2015},
      eprint={1508.06576},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1508.06576}, 
}

@misc{Zhang2018,
      title={The Unreasonable Effectiveness of Deep Features as a Perceptual Metric}, 
      author={Richard Zhang and Phillip Isola and Alexei A. Efros and Eli Shechtman and Oliver Wang},
      year={2018},
      eprint={1801.03924},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1801.03924}, 
}

@INPROCEEDINGS{Zhang2012,
  author={Zhang, Lin and Li, Hongyu},
  booktitle={2012 19th IEEE International Conference on Image Processing}, 
  title={SR-SIM: A fast and high performance IQA index based on spectral residual}, 
  year={2012},
  volume={},
  number={},
  pages={1473-1476},
  keywords={Indexes;Visualization;Image quality;Computational modeling;IP networks;Computational efficiency;Humans;IQA;visual saliency;spectral residual},
  doi={10.1109/ICIP.2012.6467149}}
