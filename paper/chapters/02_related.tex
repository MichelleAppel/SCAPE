\section{Related Work}
Encoding strategies for prosthetic vision have evolved from simple heuristic preprocessing to learned encoders and patient-specific pipelines. However, most prior methods treat the visual field uniformly, overlooking the spatial inhomogeneity imposed by cortical magnification and implant geometry. Below we review these approaches and highlight the need for adaptive methods such as SCAPE.

\subsection{Image Processing for Visual Prostheses}
Early and recent encoders have focused on extracting salient features or learning mappings to electrode activations, but they rarely incorporate the sampling constraints of individual implants. Ignoring these constraints risks oversmoothing detail in dense regions or overwhelming sparse regions with clutter. SCAPE addresses this gap by explicitly linking electrode density to filter scale.

\subsubsection{Early Heuristic Methods}
Under severe electrode count and bandwidth limits, early pipelines enhanced contrast, equalized histograms, or applied gradient-based edge detectors such as Sobel and Canny to emphasize contours in low-resolution phosphene maps \cite{Liu2005,Oh2024}. Outputs were often binarized or morphologically filtered to reduce noise and highlight obstacles or object boundaries. These methods were computationally efficient but processed the field uniformly, with no adjustment to electrode layout or cortical magnification. This uniformity limited their ability to balance detail and clutter.

\subsubsection{More Recent Learned Encodings}
Later approaches framed encoding as an optimization problem. Relic et al.\ trained convolutional networks end-to-end with a differentiable phosphene simulator on MNIST \cite{Relic2022}. Granley et al.\ proposed hybrid neural autoencoders that invert neuroscientific forward models to produce patient-specific stimulation patterns \cite{Granley2022}. De Ruyter van Steveninck et al.\ extended this to jointly optimize spatial filtering and electrode selection in an end-to-end learned encoder \cite{deRuytervanSteveninck2020}. These methods improved fidelity over heuristics but still did not explicitly modulate spatial scale based on local sampling density or magnification, leaving a gap that SCAPE fills.

\subsection{Simulated Prosthetic Vision Pipelines}
Simulation frameworks have been crucial for both developing and benchmarking encoders. Early work rendered static Gaussian phosphenes without retinotopy or magnification due to limited tools. Later immersive VR-SPV systems allowed user studies but still relied on non-differentiable heuristics and uniform phosphene shapes \cite{Kasowski2022}. Recently, van der Grinten et al.\ released a differentiable simulator in PyTorch that integrates retinotopic projection, cortical magnification, current spread, and temporal dynamics \cite{vanderGrinten2024}. This enables gradient-based optimization of encoders in realistic implant layouts. However, even with such simulators, most encoding methods still apply uniform processing, rather than adapting filter scale to local density.

 Simulation frameworks have been crucial for both developing and benchmarking encoders. Early work rendered static Gaussian phosphenes without retinotopy or magnification due to limited tools. Later immersive VR-SPV systems allowed user studies but still relied on non-differentiable heuristics and uniform phosphene shapes \cite{Kasowski2022}. Recently, van der Grinten et al.\ released a differentiable simulator in PyTorch that integrates retinotopic projection, cortical magnification, current spread, and temporal dynamics \cite{vanderGrinten2024}. This enables gradient-based optimization of encoders in realistic implant layouts. In a similar state-of-the-art effort, Fine and Boynton introduced a virtual patient model \cite{Fine2024} which allows to explore the physiological constraints of targeting V1 to generate phosphene percepts, and offers insights into both the limitations and opportunities of encoding visual information through phosphene vision. However, even with such simulators, most encoding methods still apply uniform processing, rather than adapting filter scale to the phosphene mapâ€™s local density.

\subsection{Adaptive and Spatially-Varying Encoding Approaches}
Recent methods aim for patient-specific adaptation. Granley et al.\ introduced a human-in-the-loop Bayesian optimization framework to tune deep encoders to subjective feedback \cite{Granley2023}. Hybrid autoencoders have inverted biophysical forward models to generate customized stimulation patterns \cite{Granley2022,deRuytervanSteveninck2020}. These approaches personalize encoders but do so globally, without explicitly varying processing scale across the visual field. To our knowledge, no prior method adapts filtering continuously to local electrode density or Nyquist limits. SCAPE directly addresses this unmet need by coupling density estimation with shift-variant filtering.
