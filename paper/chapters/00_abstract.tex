Visual cortical implants aim to restore sight by electrically stimulating neurons through an array of electrodes. Existing encoding methods apply uniform or global image filters without accounting for the uneven spatial sampling imposed by the implant layout. We introduce SCAPE (Shift-variant Corticaliimplant Adaptive Phosphene Encoding), a principled framework that adapts image processing to local electrode density. First, electrode coordinates are projected into visual field space and used to compute a continuous sampling density map via analytic magnification models or kernel density estimation. Next, Nyquist principles convert this density into a spatial scale map that specifies the highest resolvable frequency at each location. Finally, shift variant filtering applies a spatial kernel at each pixel whose width matches the local resolution limit. In an efficient example we implement a difference of Gaussians with separable convolutions, though SCAPE supports any kernel family. Integrated with a reconstruction decoder, SCAPE preserves structural detail and improves reconstruction accuracy across diverse natural scenes and implant configurations. By always presenting the appropriate amount of detail, SCAPE is compatible with any cortical implant scheme and paves the way for future behavioral and clinical studies.
